{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de optimización no lineal sin restricciones\n",
    "----------------\n",
    "\n",
    "## Autores\n",
    "* Quesada, Francisco\n",
    "* Serpe, Octavio\n",
    "* Arca, Gonzalo\n",
    "\n",
    "-----------------\n",
    "\n",
    "## Librerías utilizadas\n",
    "* SciPy\n",
    "* NumPy\n",
    "-----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import time\n",
    "from autograd.misc.optimizers import adam\n",
    "import numdifftools as nd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_REAL = -10\n",
    "MAX_REAL = 10\n",
    "\n",
    "NUMBER_OF_PARAMETERS = 11\n",
    "\n",
    "DATASET_INPUT = [(4.4793, -4.0765, -4.0765), (-4.1793, -\n",
    "                                              4.9218, 1.7664), (-3.9429, -0.7689, 4.8830)]\n",
    "\n",
    "DATASET_OUTPUT = [0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W 3 element vector\n",
    "# w 2x3 matrix as 6 element vector\n",
    "# w_0 2 element vector\n",
    "# reactive_values 3 element vector\n",
    "def f(W, w, w_0, reactive_values):\n",
    "    inner_g_input = 0\n",
    "    outer_g_input = 0\n",
    "\n",
    "    for j in range(2):\n",
    "        for k in range(3):\n",
    "            inner_g_input += w[k + (j * 3)] * reactive_values[k] - w_0[j]\n",
    "        outer_g_input += W[j] * g(inner_g_input)\n",
    "    return g(outer_g_input - W[0])\n",
    "\n",
    "\n",
    "# dataset_input 3 element vector\n",
    "# dataset_output 3 element vector\n",
    "def error(x, dataset_input, dataset_output):\n",
    "    #dataset_input, dataset_output = dataset_tuple\n",
    "    error = 0\n",
    "\n",
    "    W = x[0:3]\n",
    "    w = x[3:9]\n",
    "    w_0 = x[9:11]\n",
    "\n",
    "    for i in range(len(dataset_input)):\n",
    "        error += math.pow(dataset_output[i] -\n",
    "                          f(W, w, w_0, dataset_input[i]), 2)\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "def g(x):\n",
    "    # If over the limit, return the limit value\n",
    "    try:\n",
    "        exp_value = math.exp(x)\n",
    "    except OverflowError:\n",
    "        return 1\n",
    "\n",
    "    return exp_value / (1 + exp_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(x, time):\n",
    "  print(f'Argumentos óptimos:\\nW = \\t{x[0:3]}\\nw = \\t{x[3:6]}\\n\\t{x[6:9]}\\nw_0 = \\t{x[9:11]}\\n')\n",
    "  print(f'error: {error(x, DATASET_INPUT, DATASET_OUTPUT)}')\n",
    "  print(\"Tiempo de ejecucion:\", time, \"segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 1: Gradiente descendiente (método quasi-Newton BFGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 18\n",
      "         Function evaluations: 348\n",
      "         Gradient evaluations: 29\n",
      "Argumentos óptimos:\n",
      "W = \t[120.31511331  12.49538164  -0.44308898]\n",
      "w = \t[-0.07014637  1.98101769  8.15875882]\n",
      "\t[ 8.86167311 -1.89650646  0.26949546]\n",
      "w_0 = \t[-4.84091046 -7.38824611]\n",
      "\n",
      "error: 2.8033628296407015e-11\n",
      "Tiempo de ejecucion: 0.012781590994563885 segundos\n"
     ]
    }
   ],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/optimize.minimize-bfgs.html\n",
    "\n",
    "x0 = np.random.uniform(low=MIN_REAL, high=MAX_REAL, size=NUMBER_OF_PARAMETERS)\n",
    "start_time = time.perf_counter()\n",
    "optimizeResult = minimize(error, x0, method='BFGS', args=(DATASET_INPUT, DATASET_OUTPUT), tol=1e-10, options={\"disp\":True})\n",
    "end_time = time.perf_counter()\n",
    "print_output(optimizeResult.x, end_time - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 2: Gradientes conjugados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 15\n",
      "         Function evaluations: 2064\n",
      "         Gradient evaluations: 172\n",
      "Argumentos óptimos:\n",
      "W = \t[23.57285064 12.8033453  -7.87426544]\n",
      "w = \t[-22.02913189 -28.28594493  11.52666476]\n",
      "\t[-21.05058058 -13.83270459  -0.63832122]\n",
      "w_0 = \t[-9.85813742 -6.82608443]\n",
      "\n",
      "error: 1.515099540561219e-11\n",
      "Tiempo de ejecucion: 0.0532665420032572 segundos\n"
     ]
    }
   ],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/optimize.minimize-cg.html\n",
    "\n",
    "x0 = np.random.uniform(low=MIN_REAL, high=MAX_REAL, size=NUMBER_OF_PARAMETERS)\n",
    "start_time = time.perf_counter()\n",
    "optimizeResult = minimize(error, x0, method='CG', args=(DATASET_INPUT, DATASET_OUTPUT), tol=1e-10, options={\"disp\":True})\n",
    "end_time = time.perf_counter()\n",
    "print_output(optimizeResult.x, end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 3: ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación del método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argumentos óptimos:\n",
      "W = \t[ 9.93544931  7.56192883 -5.94339096]\n",
      "w = \t[-8.49543877  2.38929764  3.89335269]\n",
      "\t[-3.92431511 -1.84599246  9.67275032]\n",
      "w_0 = \t[-12.98182375   0.73115958]\n",
      "\n",
      "error: 5.423162050837844e-07\n",
      "Tiempo de ejecucion: 0.6321328709964291 segundos\n"
     ]
    }
   ],
   "source": [
    "x0 = np.random.uniform(low=MIN_REAL, high=MAX_REAL, size=NUMBER_OF_PARAMETERS)\n",
    "gradient = nd.Gradient(error)\n",
    "def grad(x,i):\n",
    "    return gradient(x, DATASET_INPUT, DATASET_OUTPUT)\n",
    "\n",
    "values = []\n",
    "steps = 0\n",
    "gradients = []\n",
    "\n",
    "def save_values(x,i,g):\n",
    "    values.append(x)\n",
    "    gradients.append(g)\n",
    "    steps = i\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "optimizeResult = adam(grad,x0,step_size= 0.8,callback=save_values,num_iters=100)\n",
    "end_time = time.perf_counter()\n",
    "print_output(optimizeResult, end_time - start_time) \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d39c3dda0d45297420c0d8fc1cf706a4a2909234f3473c84dddd2ffa0a641241"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('non-linear-optimization-methods-gr2b39L-')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
